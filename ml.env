MACHINE_LEARNING_MODEL_TTL=            #? Inactivity time (s) before a model is unloaded (disabled if <= 0), default: 300
MACHINE_LEARNING_MODEL_TTL_POLL_S=10   #? Interval (s) between checks for the model TTL (disabled if <= 0), default:	10
MACHINE_LEARNING_CACHE_FOLDER='/cache' #? Directory where models are downloaded, default:	'/cache'
#! See Footer *1
# MACHINE_LEARNING_REQUEST_THREADS= #? (*1)	Thread count of the request thread pool (disabled if <= 0), default: `number of CPU cores`
# MACHINE_LEARNING_MODEL_INTER_OP_THREADS=1	#? Number of parallel model operations, default:	1
MACHINE_LEARNING_MODEL_INTRA_OP_THREADS=2 #?	Number of threads for each model operation, default:	2
#! See Footer *2
MACHINE_LEARNING_WORKERS=1 #? (*2)	Number of worker processes to spawn, default:	1
#! See Footer *3
MACHINE_LEARNING_HTTP_KEEPALIVE_TIMEOUT_S=2 #? (*3)	HTTP Keep-alive time in seconds, default:	2
MACHINE_LEARNING_WORKER_TIMEOUT=120         #? Maximum time (s) of unresponsiveness before a worker is killed, default:	120 | 300 -- if using OpenVINO
# MACHINE_LEARNING_PRELOAD__CLIP=	#? Name of a CLIP model to be preloaded and kept in cache, default: `none`
# MACHINE_LEARNING_PRELOAD__FACIAL_RECOGNITION=	#? Name of a facial recognition model to be preloaded and kept in cache, default: `none`
MACHINE_LEARNING_ANN=True             #? Enable ARM-NN hardware acceleration if supported, default:	True
MACHINE_LEARNING_ANN_FP16_TURBO=False #? Execute operations in FP16 precision: increasing speed, reducing precision (applies only to ARM-NN), default: False
MACHINE_LEARNING_ANN_TUNING_LEVEL=2   #? ARM-NN GPU tuning level (1: rapid, 2: normal, 3: exhaustive), default:	2
#! See Footer *4
MACHINE_LEARNING_DEVICE_IDS=0 #? (*4)	Device IDs to use in multi-GPU environments, default:	0
# MACHINE_LEARNING_MAX_BATCH_SIZE__FACIAL_RECOGNITION= #?	Set the maximum number of faces that will be processed at once by the facial recognition model, default: `none` | 1 -- if using OpenVINO
# *1: It is recommended to begin with this parameter when changing the concurrency levels
#*      of the machine learning service and then tune the other ones.
# *2: Since each process duplicates models in memory,
#*      changing this is not recommended unless you have abundant memory to go around.
# *3: For scenarios like HPA in K8S. https://github.com/immich-app/immich/discussions/12064
# *4: Using multiple GPUs requires`MACHINE_LEARNING_WORKERS` to be set greater than 1.
#*      A single device is assigned to each worker in round-robin priority.
